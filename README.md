# Лабораторная работа: Обучение перцептрона 

## Цель

Реализовать и обучить однослойный перцептрон на синтетических данных. Выполнить нормализацию признаков, оценить точность модели.

---

## Используемые библиотеки

| Библиотека         | Назначение                                                         |
|--------------------|--------------------------------------------------------------------|
| `numpy`            | Векторные и матричные вычисления                                   |
| `pandas`           | Работа с таблицами и сохранение датасета в CSV                    |
| `matplotlib.pyplot`| Построение графиков (ошибка и веса)                               |
| `sklearn.datasets` | Генерация синтетического классификационного датасета              |
| `sklearn.preprocessing` | Нормализация данных (стандартизация признаков)            |

---

## Алгоритм: Перцептрон

Модель представляет собой **однослойный перцептрон** с пороговой функцией активации:

- Весовые коэффициенты инициализируются случайно
- Обновление весов выполняется по правилу: w = w + learning_rate * (d - y) * x
- Функция активации: activation(z) = 1, если z >= 0, иначе activation(z) = 0

  
---

## Этапы работы

### 1. Генерация данных

С помощью `make_classification` создаётся 300 примеров с 10 признаками, 5 из которых — информативны.

### 2. Нормализация

Признаки стандартизируются с помощью `StandardScaler` для улучшения сходимости обучения.

### 3. Обучение

Параметры модели:
- `learning_rate = 0.05`
- `epochs = 800`

### 4. Оценка точности

После обучения модель тестируется на данных, и выводится доля правильных предсказаний.

---

## Визуализация

### Ошибка по эпохам

Показывает, как уменьшается количество ошибок в процессе обучения:

![image](https://github.com/user-attachments/assets/2763da0e-50a8-42c5-82cb-359d50aad796)


### Веса модели

Позволяет понять, какие признаки оказали большее влияние на классификацию:

![image](https://github.com/user-attachments/assets/b827f455-f729-4939-98a2-86827c91a16c)


---

## Результаты

- Точность на тестовой выборке: **~75-85%**
- Ошибка обучения постепенно снижается
- Наиболее значимые признаки получают более высокие веса

---

## Сохранение данных

Сгенерированный и нормализованный датасет сохраняется в файл: 'large_dataset.csv'


